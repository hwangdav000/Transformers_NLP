{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12103,"status":"ok","timestamp":1671695467467,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"bTWgE9ERqPuL","outputId":"b9f01233-d089-40be-acd5-960999554309"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 29.4 MB/s \n","\u001b[?25hCollecting huggingface-hub\u003c1.0,\u003e=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 96.1 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: tqdm\u003e=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,\u003c0.14,\u003e=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 84.4 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.10.0-\u003etransformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,\u003e=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging\u003e=20.0-\u003etransformers) (3.0.9)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (1.24.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (2022.12.7)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (2.10)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests-\u003etransformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":6444,"status":"ok","timestamp":1671695473908,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"5CClDElebJKS"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_importer_cache\u001b[0;34m(cls, path)\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/types'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-2-582406613f17\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m from .utils import (\n\u001b[1;32m     32\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---\u003e 34\u001b[0;31m from .generic import (\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mContextManagers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 33\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 51\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__internal__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__operators__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 33\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtpu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 68\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/_api/v2/compat/v2/types/__init__.py\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_spec\u001b[0;34m(name, path, target)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mfind_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_get_spec\u001b[0;34m(cls, fullname, path, target)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_importer_cache\u001b[0;34m(cls, path)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_hooks\u001b[0;34m(cls, path)\u001b[0m\n","\u001b[0;32m\u003cfrozen zipimport\u003e\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path)\u001b[0m\n","\u001b[0;32m/usr/lib/python3.8/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36m_path_stat\u001b[0;34m(path)\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Importing the libraries needed\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn import preprocessing\n","import torch\n","import seaborn as sns\n","import transformers\n","import json\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import  BertTokenizer, BertModel\n","import logging\n","logging.basicConfig(level=logging.ERROR)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":297,"status":"ok","timestamp":1671695482610,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"YlJFWzVzbLfF","outputId":"64f47aa1-a482-48d2-b96c-bd397f748812"},"outputs":[{"data":{"text/plain":["device(type='cuda')"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Setting up the device for GPU usage\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10671,"status":"ok","timestamp":1671695496012,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"ti7z8wjOp93r","outputId":"0da8ac54-933b-45a3-f9d0-ed275ebf26ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-12-22 07:51:25--  https://nlp.stanford.edu/projects/snli/snli_1.0.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 94550081 (90M) [application/zip]\n","Saving to: ‘snli_1.0.zip’\n","\n","snli_1.0.zip        100%[===================\u003e]  90.17M  17.0MB/s    in 9.5s    \n","\n","2022-12-22 07:51:36 (9.47 MB/s) - ‘snli_1.0.zip’ saved [94550081/94550081]\n","\n"]}],"source":["!wget https://nlp.stanford.edu/projects/snli/snli_1.0.zip"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3488,"status":"ok","timestamp":1671695499496,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"rwhJT2Kip_TE","outputId":"b192cef4-4f9e-420d-cbab-62118a73a8f1"},"outputs":[{"name":"stdout","output_type":"stream","text":["File Name                                             Modified             Size\n","snli_1.0/                                      2015-08-29 08:57:10            0\n","snli_1.0/.DS_Store                             2015-08-29 08:57:16         6148\n","__MACOSX/                                      2015-08-29 09:00:04            0\n","__MACOSX/snli_1.0/                             2015-08-29 09:00:04            0\n","__MACOSX/snli_1.0/._.DS_Store                  2015-08-29 08:57:16          120\n","snli_1.0/Icon\r                                 2015-05-21 16:21:08            0\n","__MACOSX/snli_1.0/._Icon\r                      2015-05-21 16:21:08       340709\n","snli_1.0/README.txt                            2015-08-29 08:59:48         5828\n","__MACOSX/snli_1.0/._README.txt                 2015-08-29 08:59:48          171\n","snli_1.0/snli_1.0_dev.jsonl                    2015-08-17 10:34:22      9745714\n","snli_1.0/snli_1.0_dev.txt                      2015-08-17 10:34:24      7565773\n","snli_1.0/snli_1.0_test.jsonl                   2015-08-17 10:34:26      9730457\n","snli_1.0/snli_1.0_test.txt                     2015-08-17 10:34:28      7550390\n","snli_1.0/snli_1.0_train.jsonl                  2015-08-17 10:34:52    487457790\n","snli_1.0/snli_1.0_train.txt                    2015-08-17 10:35:12    375697923\n","__MACOSX/._snli_1.0                            2015-08-29 08:57:10          120\n","Extracting all the files now...\n","Done!\n"]}],"source":["from zipfile import ZipFile\n","# specifying the zip file name\n","file_name = \"snli_1.0.zip\"\n","# opening the zip file in READ mode\n","with ZipFile(file_name, 'r') as zip:\n","    # printing all the contents of the zip file\n","    zip.printdir()\n","    # extracting all the files\n","    print('Extracting all the files now...')\n","    zip.extractall()\n","    print('Done!')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4537,"status":"ok","timestamp":1671695504027,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"aDUTCWqxsJE1"},"outputs":[],"source":["import pandas as pd\n","#load dataset\n","train_dataset = pd.read_csv('snli_1.0/snli_1.0_train.txt', sep='\\t')\n","valid_dataset = pd.read_csv('snli_1.0/snli_1.0_dev.txt', sep='\\t')\n","test_dataset = pd.read_csv('snli_1.0/snli_1.0_test.txt', sep='\\t')"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":452,"status":"ok","timestamp":1671695716994,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"eu8aRehOWrFH","outputId":"35ffd76b-7a0a-4bad-de6f-8501f4ba32fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["(150000, 3)\n","(10000, 3)\n","(10000, 3)\n"]}],"source":["#Get neccesary columns\n","# label, premise, hypothesis\n","df_train = train_dataset[['gold_label','sentence1','sentence2']]\n","df_dev = valid_dataset[['gold_label','sentence1','sentence2']]\n","df_test = test_dataset[['gold_label','sentence1','sentence2']]\n","\n","df_train = df_train[:150000]\n","print(df_train.shape)\n","print(df_dev.shape)\n","print(df_test.shape)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":454,"status":"ok","timestamp":1671695721022,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"lzoS2uDwWu7q","outputId":"2dde5593-6138-4e53-e8a3-dc1ba936188e"},"outputs":[{"name":"stdout","output_type":"stream","text":["(149823, 3)\n","(9842, 3)\n","(9824, 3)\n"]}],"source":["# filtering the rows where label is not valid\n","df_train = df_train[~df_train['gold_label'].str.contains('-')]\n","df_dev = df_dev[~df_dev['gold_label'].str.contains('-')]\n","df_test = df_test[~df_test['gold_label'].str.contains('-')]\n","\n","print(df_train.shape)\n","print(df_dev.shape)\n","print(df_test.shape)"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":487,"status":"ok","timestamp":1671695721508,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"uqLGhdVep39g","outputId":"9f69ecc0-34e3-44aa-9d06-371845119e9b"},"outputs":[{"name":"stdout","output_type":"stream","text":["402\n","204.0\n","300\n","232\n","265\n","159\n"]}],"source":["#Check longest string in Phrase\n","print(df_train.sentence1.str.len().max())\n","print(df_train.sentence2.str.len().max())\n","\n","print(df_dev.sentence1.str.len().max())\n","print(df_dev.sentence2.str.len().max())\n","\n","print(df_test.sentence1.str.len().max())\n","print(df_test.sentence2.str.len().max())"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1671695722180,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"k-WGDqDDp39g","outputId":"1db8fed7-e172-4c25-da20-b802f9dd5250"},"outputs":[{"name":"stdout","output_type":"stream","text":["(81057, 3)\n","(4678, 3)\n","(4639, 3)\n"]}],"source":["# remove all strings greater than 64\n","df_train = df_train[~df_train['sentence1'].str.len().ge(64)]\n","df_train = df_train[~df_train['sentence2'].str.len().ge(64)]\n","\n","df_dev = df_dev[~df_dev['sentence1'].str.len().ge(64)]\n","df_dev = df_dev[~df_dev['sentence2'].str.len().ge(64)]\n","\n","df_test = df_test[~df_test['sentence1'].str.len().ge(64)]\n","df_test = df_test[~df_test['sentence2'].str.len().ge(64)]\n","\n","print(df_train.shape)\n","print(df_dev.shape)\n","print(df_test.shape)\n"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1671695722895,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"4Bd2RGKzWx3E","outputId":"20b35fa8-950c-4554-ac47-0413f1a3e368"},"outputs":[{"name":"stdout","output_type":"stream","text":["[2 0 1]\n","[1 0 2]\n","[2 1 0]\n"]}],"source":["# label_encoder object knows how to understand word labels.\n","label_encoder = preprocessing.LabelEncoder()\n","  \n","# Encode labels in column for gold_label\n","df_train['gold_label']= label_encoder.fit_transform(df_train['gold_label'])\n","print(df_train['gold_label'].unique())\n","# Encode labels in column for gold_label\n","df_dev['gold_label']= label_encoder.fit_transform(df_dev['gold_label'])\n","print(df_dev['gold_label'].unique())\n","# Encode labels in column for gold_label\n","df_test['gold_label']= label_encoder.fit_transform(df_test['gold_label'])\n","print(df_test['gold_label'].unique())"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":1307,"status":"ok","timestamp":1671695724937,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"VdtQvq6nW0et"},"outputs":[],"source":["# from transformers import GPT2Tokenizer, GPT2Model\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1671695724937,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"D6dc32qXXgFh"},"outputs":[],"source":["import string\n","\n","def trim_sentence(sent):\n","    try:\n","        sent = sent.split()\n","        sent = sent[:64]\n","        return \" \".join(sent)\n","    except:\n","        return sent\n","\n","def NLIData( dataframe, tokenizer, max_len):\n","    df = pd.DataFrame()\n","\n","    for index in dataframe.index:\n","\n","        premise = str(dataframe['sentence1'][index])\n","        premise = trim_sentence(premise.translate(str.maketrans('', '', string.punctuation))) + \" . \"\n","        \n","        hypothesis = str(dataframe['sentence2'][index])\n","        hypothesis = trim_sentence(hypothesis.translate(str.maketrans('', '', string.punctuation)))\n","        label = dataframe['gold_label'][index]\n","\n","        # tokenize input\n","        tokenized_input_seq_pair = tokenizer(\n","            premise,\n","            hypothesis,\n","            max_length=max_len,\n","            pad_to_max_length= True,\n","            return_token_type_ids=True,\n","            return_tensors='pt',\n","            truncation=True,\n","            )\n","    \n","\n","        ids = tokenized_input_seq_pair['input_ids']\n","        mask = tokenized_input_seq_pair['attention_mask']\n","        token_type_ids = tokenized_input_seq_pair[\"token_type_ids\"]\n","        text = premise + hypothesis\n","      \n","        df = df.append({\n","            'text': text, \n","            'ids': ids.flatten(),\n","            'mask': mask.flatten(),\n","            'tti': token_type_ids.flatten(),\n","            'labels': torch.tensor(label, dtype=torch.long)\n","        }, ignore_index=True)\n","    return df"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1,"status":"ok","timestamp":1671695725434,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"409l3fhkp39i","outputId":"e9e881a9-2b37-49cd-c3ee-1099114de7f3"},"outputs":[{"name":"stdout","output_type":"stream","text":["63\n","63.0\n","63\n","63\n","63\n","63\n"]}],"source":["#Check longest string in Phrase\n","print(df_train.sentence1.str.len().max())\n","print(df_train.sentence2.str.len().max())\n","\n","print(df_dev.sentence1.str.len().max())\n","print(df_dev.sentence2.str.len().max())\n","\n","print(df_test.sentence1.str.len().max())\n","print(df_test.sentence2.str.len().max())"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1671695726326,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"rmkMQD4up39i","outputId":"0f9c16bc-8fb3-407c-e230-452da29a0d35"},"outputs":[{"name":"stdout","output_type":"stream","text":["Int64Index([], dtype='int64')\n","Int64Index([], dtype='int64')\n","Int64Index([], dtype='int64')\n","Int64Index([], dtype='int64')\n","Int64Index([], dtype='int64')\n","Int64Index([], dtype='int64')\n"]}],"source":["print(df_train[df_train['sentence1'] == ' '].index)\n","print(df_train[df_train['sentence2'] == ' '].index)\n","\n","print(df_dev[df_dev['sentence1'] == ' '].index)\n","print(df_dev[df_dev['sentence2'] == ' '].index)\n","\n","print(df_test[df_test['sentence1'] == ' '].index)\n","print(df_test[df_test['sentence2'] == ' '].index)"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":494245,"status":"ok","timestamp":1671696220570,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"U7uN1rsPXwjR","outputId":"54931e12-318c-4656-bf5d-938907118f4a"},"outputs":[{"name":"stdout","output_type":"stream","text":["FULL Dataset: (81057, 5)\n","TRAIN Dataset: (4678, 5)\n","TEST Dataset: (4639, 5)\n"]}],"source":["# Defining some key variables that will be used later on in the training\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","MAX_LEN = 128\n","LEARNING_RATE = 5e-5\n","\n","# get the sets \n","train_set = NLIData(df_train, tokenizer, MAX_LEN)\n","valid_set = NLIData(df_dev, tokenizer, MAX_LEN)\n","test_set = NLIData(df_test, tokenizer, MAX_LEN)\n","\n","print(\"FULL Dataset: {}\".format(train_set.shape))\n","print(\"TRAIN Dataset: {}\".format(valid_set.shape))\n","print(\"TEST Dataset: {}\".format(test_set.shape))"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":314,"status":"ok","timestamp":1671696231742,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"rjCVqgVUWw2j"},"outputs":[],"source":["#Convert dataframe to dataset\n","from torch.utils.data import Dataset\n","\n","class PandasDataset(Dataset):\n","    def __init__(self, dataframe):\n","        self.dataframe = dataframe\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, index):\n","        row = self.dataframe.iloc[index]\n","        ids, mask, label, tti= row[\"ids\"], row[\"mask\"], row[\"labels\"], row[\"tti\"]\n","        return {\"ids\": ids, \n","                \"mask\":mask, \n","                \"label\":label,\n","                \"tti\": tti\n","                }\n","\n","train_dataset = PandasDataset(train_set)\n","valid_dataset = PandasDataset(valid_set)\n","test_dataset = PandasDataset(test_set)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":290,"status":"ok","timestamp":1671696234547,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"y9dFZExVebS8"},"outputs":[],"source":["TRAIN_BATCH_SIZE = 32\n","VALID_BATCH_SIZE = 32\n","\n","train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","val_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","train_loader = DataLoader(train_dataset, **train_params)\n","valid_loader = DataLoader(valid_dataset, **val_params)\n","test_loader = DataLoader(test_dataset, **test_params)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"elapsed":9368,"status":"ok","timestamp":1671696246370,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"Mb-v5cmfrTIk","outputId":"48bb7d15-2f00-443f-e091-f5ac5c414122"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ee875464dd8499292a630c4f3744f95","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/440M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["from transformers import BertModel\n","bert_model = BertModel.from_pretrained('bert-base-uncased')"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2530,"status":"ok","timestamp":1671696413718,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"uFMmlEM13uG3","outputId":"b6de6669-e85d-438d-e00e-89445242dfac"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# Load the basic BERT model \n","bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1671696413718,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"B-zaxp0gtWJZ"},"outputs":[],"source":["class BERTClass(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTClass, self).__init__()\n","        self.l1 = BertModel.from_pretrained(\"bert-base-uncased\")\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(0.3)\n","        self.classifier = torch.nn.Linear(768, 5)\n","\n","    def forward(self, input_ids, attention_mask):\n","        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n","        hidden_state = output_1[0]\n","        pooler = hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2663,"status":"ok","timestamp":1671696421112,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"Z4c4Qp3Z1byU","outputId":"1df46e65-e400-4796-e9e0-5372eaa65966"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"data":{"text/plain":["BERTClass(\n","  (l1): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",")"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["model = BERTClass()\n","model.to(device)"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":295,"status":"ok","timestamp":1671696438738,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"yMEQWNVv1yA_"},"outputs":[],"source":["# Creating the loss function and optimizer\n","EPOCHS = 1\n","\n","loss_fn = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":313,"status":"ok","timestamp":1671696444496,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"0yDA6hgYp39k"},"outputs":[],"source":["# Function for a single training iteration\n","def train_epoch(model, training_loader, loss_fn, optimizer, device, n_examples):\n","    model = model.train()\n","    losses = []\n","    correct_predictions = 0\n","    step = 0\n","    for d in tqdm(training_loader):\n","        step = step+1\n","        input_ids = d[\"ids\"].to(device)\n","        attention_mask = d[\"mask\"].to(device)\n","        targets = d[\"label\"].to(device)\n","        #tti = d[\"tti\"].to(device)\n","        \n","        outputs = model(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask,\n","            #token_type_ids=tti\n","        )\n","        \n","        _, preds = torch.max(outputs, dim=1)\n","        loss = loss_fn(outputs, targets)\n","        correct_predictions += torch.sum(preds == targets)\n","        losses.append(loss.item())\n","        \n","        # Backward prop\n","        loss.backward()\n","        \n","        # Gradient Descent\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","        optimizer.step()\n","        #scheduler.step()\n","        optimizer.zero_grad()\n","    \n","    \n","    return correct_predictions.double() / n_examples, np.mean(losses)"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":313,"status":"ok","timestamp":1671696449654,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"Y4INvi46p39k"},"outputs":[],"source":["def eval_model(model, data_loader, loss_fn, device, n_examples):\n","    model = model.eval()\n","    \n","    losses = []\n","    correct_predictions = 0\n","    \n","    with torch.no_grad():\n","        for d in tqdm(data_loader):\n","            input_ids = d[\"ids\"].to(device)\n","            attention_mask = d[\"mask\"].to(device)\n","            targets = d[\"label\"].to(device)\n","            #tti = d[\"tti\"].to(device)\n","            \n","            # Get model ouptuts\n","            outputs = model(\n","                input_ids,\n","                attention_mask,\n","                #tti\n","            )\n","            \n","            _, preds = torch.max(outputs, dim=1)\n","            loss = loss_fn(outputs, targets)\n","            \n","            correct_predictions += torch.sum(preds == targets)\n","            losses.append(loss.item())\n","            \n","    return correct_predictions.double() / n_examples, np.mean(losses)"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":474557,"status":"ok","timestamp":1671696926355,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"0adWTBHn7LwM","outputId":"fd4e9602-12d5-4613-848a-bf460e9b2095","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/1\n","----------\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2534/2534 [07:45\u003c00:00,  5.44it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss 0.5323462185538841 accuracy 0.7900243038849205\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 147/147 [00:07\u003c00:00, 18.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Val   loss 0.4063702160809316 accuracy 0.847798204360838\n","\n","CPU times: user 7min 52s, sys: 2.04 s, total: 7min 54s\n","Wall time: 7min 54s\n"]}],"source":["%%time\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","from collections import defaultdict\n","\n","history = defaultdict(list)\n","best_accuracy = 0\n","\n","for epoch in range(EPOCHS):\n","    \n","    # Show details \n","    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n","    print(\"-\" * 10)\n","    \n","    train_acc, train_loss = train_epoch(\n","        model,\n","        train_loader,\n","        loss_fn,\n","        optimizer,\n","        device,\n","        len(train_set)\n","    )\n","    \n","    print(f\"Train loss {train_loss} accuracy {train_acc}\")\n","    \n","    # Get model performance (accuracy and loss)\n","    val_acc, val_loss = eval_model(\n","        model,\n","        valid_loader,\n","        loss_fn,\n","        device,\n","        len(valid_set)\n","    )\n","    \n","    print(f\"Val   loss {val_loss} accuracy {val_acc}\")\n","    print()\n","    \n","    history['train_acc'].append(train_acc)\n","    history['train_loss'].append(train_loss)\n","    history['val_acc'].append(val_acc)\n","    history['val_loss'].append(val_loss)\n","    \n","    # If we beat prev performance\n","    if val_acc \u003e best_accuracy:\n","        torch.save(model.state_dict(), 'BERT_NLI_Model')\n","        best_accuracy = val_acc"]},{"cell_type":"code","execution_count":50,"metadata":{"executionInfo":{"elapsed":1193,"status":"ok","timestamp":1671696960866,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"FUem31225v3a"},"outputs":[],"source":["torch.save(model.state_dict(), 'BERT_NLI_Model')"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1671697102662,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"ovLpaCgD6LNe","outputId":"4983f3f5-dd6e-41c1-bbc7-339b2c6080b0"},"outputs":[{"data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/javascript":["download(\"download_6a9200d3-6274-4aef-a561-ab0f62c803a6\", \"BERT_NLI_Model\", 440393547)"],"text/plain":["\u003cIPython.core.display.Javascript object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["# download checkpoint file\n","from google.colab import files\n","files.download('BERT_NLI_Model')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ycLMdLHA4YJc"},"outputs":[],"source":["#Times\n","# BERT\n","# RoBERTa\n","# GPT2\n","# GPTNeo"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1671695384637,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"GO8DXzys7VOz","scrolled":true},"outputs":[],"source":["model.load_state_dict(torch.load('BERT_NLI_Model'))\n","model = model.to(device)"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24802,"status":"ok","timestamp":1671697354252,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"Pmm1jfWS7LlW","outputId":"f0e75684-76be-4c95-8689-762862c34146"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":58,"metadata":{"executionInfo":{"elapsed":7448,"status":"ok","timestamp":1671697448787,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"ugmb197x7RmI"},"outputs":[],"source":["PATH = F\"/content/gdrive/My Drive/Models/BERT_NLI_Model\"\n","torch.save(model.state_dict(), PATH)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10150,"status":"ok","timestamp":1671697148301,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"sshIycszp39l","outputId":"454bb24b-d87a-4dcb-dcd3-4fe825912e83"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 145/145 [00:07\u003c00:00, 18.44it/s]\n"]},{"data":{"text/plain":["0.8396206078896313"]},"execution_count":53,"metadata":{},"output_type":"execute_result"}],"source":["# Get model performance (accuracy and loss)\n","test_acc, test_loss = eval_model(\n","  model,\n","  test_loader,\n","  loss_fn,\n","  device,\n","  len(test_set)\n",")\n","test_acc.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OD5jqY5T6jKR"},"outputs":[],"source":["#0.8396"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1671697162430,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"LX_xR6ndlYQN"},"outputs":[],"source":["def predict_inference(premise, hypothesis, model, device):\n","  \n","    premise = trim_sentence(premise.translate(str.maketrans('', '', string.punctuation))) + \" . \" \n","    hypothesis = trim_sentence(hypothesis.translate(str.maketrans('', '', string.punctuation)))\n","\n","    tokenized_input_seq_pair = tokenizer(\n","        premise, \n","        hypothesis,\n","        pad_to_max_length = True,\n","        max_length=MAX_LEN,\n","        return_token_type_ids=True,\n","        truncation=True,\n","        return_tensors='pt'\n","    )\n","    \n","    ids = tokenized_input_seq_pair['input_ids']\n","    mask = tokenized_input_seq_pair['attention_mask']\n","    #tti = tokenized_input_seq_pair[\"token_type_ids\"]\n","    text = premise + \". \" + hypothesis\n","  \n","    LABEL = ['contradiction', 'entailment','neutral']\n","    model.eval()\n","\n","    with torch.no_grad():\n","        sequence = ids.to(device)\n","        attn_mask = mask.to(device)\n","        #tti = tti.to(device)\n","        prediction = model(sequence, attn_mask)\n","        prediction = prediction.argmax(dim=-1).item()\n","    return LABEL[prediction]"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":360},"executionInfo":{"elapsed":10,"status":"error","timestamp":1671697169148,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"2ypVo4sSla0M","outputId":"28df332f-d1a1-48a3-bcad-e2fdd614e7db"},"outputs":[{"ename":"TypeError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-55-d2ddae1ed462\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpremise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Children smiling and waving at camera'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'There are children present'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0mpredict_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m\u003cipython-input-54-a25b7e8d35fa\u003e\u001b[0m in \u001b[0;36mpredict_inference\u001b[0;34m(premise, hypothesis, model, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mattn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mtti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtti\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 28\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtti\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mLABEL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-\u003e 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: forward() takes 3 positional arguments but 4 were given"]}],"source":["premise = 'Children smiling and waving at camera'\n","hypothesis = 'There are children present'\n","predict_inference(premise, hypothesis, model, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1671695384638,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"c8VJrcW5lb3L"},"outputs":[],"source":["premise = 'I am using mobile phone.'\n","hypothesis = 'I have mobile in my hand.'\n","\n","predict_inference(premise, hypothesis, model, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1671695384638,"user":{"displayName":"DAVID HWANG","userId":"14840029828748792565"},"user_tz":360},"id":"c5wSukMWp39m"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","version":""},"gpuClass":"premium","kernelspec":{"display_name":"pytorch_gpu","language":"python","name":"pytorch_gpu"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3e9038ba514d458f890390758adcfc87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3ee875464dd8499292a630c4f3744f95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fd3f934368b845c28c9279c16cf2b22d","IPY_MODEL_a462f07901fd494bb1e9937de9b3586e","IPY_MODEL_92f66f897f474333acfbd768e5317fcc"],"layout":"IPY_MODEL_6242663b1efd44dc9b7f016acd241d91"}},"522222ab5bc84be49c0a367fbd13dac8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6242663b1efd44dc9b7f016acd241d91":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77c3f7df21f049cea2c3ebff4c62cb3e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82b7d75e465d4995b63b01dd2722755f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92f66f897f474333acfbd768e5317fcc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_522222ab5bc84be49c0a367fbd13dac8","placeholder":"​","style":"IPY_MODEL_82b7d75e465d4995b63b01dd2722755f","value":" 440M/440M [00:05\u0026lt;00:00, 81.6MB/s]"}},"a462f07901fd494bb1e9937de9b3586e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b348e1c74a154326983ae22f13dccdea","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ec8d1a5c47e94b9e9606469960de6e90","value":440473133}},"b348e1c74a154326983ae22f13dccdea":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ec8d1a5c47e94b9e9606469960de6e90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd3f934368b845c28c9279c16cf2b22d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_77c3f7df21f049cea2c3ebff4c62cb3e","placeholder":"​","style":"IPY_MODEL_3e9038ba514d458f890390758adcfc87","value":"Downloading: 100%"}}}}},"nbformat":4,"nbformat_minor":0}