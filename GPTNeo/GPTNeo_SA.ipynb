{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "e7b5f5ab6f8f300c8900321a91b9340376c986f2",
    "id": "979OUro5Eac3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-21 12:34:37.985673: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPTNeoConfig, GPTNeoModel, GPT2Tokenizer\n",
    "from transformers import InputExample, InputFeatures\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up device for gpu usage or cpu usage\n",
    "# torch.cuda.empty_cache()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 132
    },
    "id": "J3FzcAlgEac8",
    "outputId": "4df680d5-008c-4b66-ca6a-17290a297529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PhraseId  SentenceId                                             Phrase  \\\n",
      "0         1           1  A series of escapades demonstrating the adage ...   \n",
      "1         2           1  A series of escapades demonstrating the adage ...   \n",
      "2         3           1                                           A series   \n",
      "3         4           1                                                  A   \n",
      "4         5           1                                             series   \n",
      "\n",
      "   Sentiment  \n",
      "0          1  \n",
      "1          2  \n",
      "2          2  \n",
      "3          2  \n",
      "4          2  \n",
      "   PhraseId  SentenceId                                             Phrase\n",
      "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
      "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
      "2    156063        8545                                                 An\n",
      "3    156064        8545  intermittently pleasing but mostly routine effort\n",
      "4    156065        8545         intermittently pleasing but mostly routine\n",
      "   PhraseId  Sentiment\n",
      "0    156061          2\n",
      "1    156062          2\n",
      "2    156063          2\n",
      "3    156064          2\n",
      "4    156065          2\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "train=pd.read_csv(\"../Dataset/SA_dataset/train.tsv\", sep=\"\\t\", on_bad_lines='skip')\n",
    "test=pd.read_csv(\"../Dataset/SA_dataset/test.tsv\", sep=\"\\t\", on_bad_lines='skip')\n",
    "test_check=pd.read_csv(\"../Dataset/SA_dataset/test_check.csv\", sep=\",\", on_bad_lines='skip')\n",
    "print(train.head())\n",
    "print(test.head())\n",
    "print(test_check.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "u7d_0JIDKNWa",
    "outputId": "ab24334a-335c-46e4-9b98-1e29c9ea3d71"
   },
   "outputs": [],
   "source": [
    "# df_train = train\n",
    "# df_test = test\n",
    "# df_test_c = test_check\n",
    "\n",
    "df_train = train[:int(len(train)/2)]\n",
    "df_test = test[:int(len(test)/2)]\n",
    "df_test_c = test_check[:int(len(test)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "IACLFcJtKsrX",
    "outputId": "d64d358d-5aba-47e5-b629-dbeeb54bfeca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33146"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TFIoIjucGjJw",
    "outputId": "714fd41e-8e4e-4fab-c601-c9ddc7ac4eca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>156061</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156062</td>\n",
       "      <td>8545</td>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156063</td>\n",
       "      <td>8545</td>\n",
       "      <td>An</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>156064</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>156065</td>\n",
       "      <td>8545</td>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0    156061        8545  An intermittently pleasing but mostly routine ...   \n",
       "1    156062        8545  An intermittently pleasing but mostly routine ...   \n",
       "2    156063        8545                                                 An   \n",
       "3    156064        8545  intermittently pleasing but mostly routine effort   \n",
       "4    156065        8545         intermittently pleasing but mostly routine   \n",
       "\n",
       "   Sentiment  \n",
       "0          2  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_col = df_test_c[\"Sentiment\"]\n",
    "df_test = df_test.join(extracted_col)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Phrase  Sentiment\n",
       "0  An intermittently pleasing but mostly routine ...          2\n",
       "1  An intermittently pleasing but mostly routine ...          2\n",
       "2                                                 An          2\n",
       "3  intermittently pleasing but mostly routine effort          2\n",
       "4         intermittently pleasing but mostly routine          2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train[['Phrase', 'Sentiment']]\n",
    "df_test = df_test[['Phrase', 'Sentiment']]\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n",
      "256\n"
     ]
    }
   ],
   "source": [
    "#Check longest string in Phrase\n",
    "print(df_train.Phrase.str.len().max())\n",
    "print(df_test.Phrase.str.len().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "f3c039795b634c1b89ece4a35815533e",
      "f94c8764e7eb4245b64bcc20b2cf2f9f",
      "80599af641ca43509eab85f43069c2b9",
      "0e9457ca4249484697572c3b07cb3d21",
      "17da5e15286b47c9a7bec9592111b72f",
      "11ba5b834bda4174a2f3d9d4f36881c3",
      "4c7fc2c48f9b439dbfe73cf74de76c8b",
      "715932841e174fdba262ba1e5ae5f5c6",
      "ef665c9eee4942598abcb1be9588dd94",
      "657c1c6a696b47e0a92a84a2a1672604",
      "639b7315d6ca4a7384d2a2a3306c75b0",
      "8ed024db83014418a687d99091e5fce2",
      "65cdd43e32084e11b028b9dcc0da682a",
      "795103d24e494175be849536604a154f",
      "d4a912c8a844499d8f0ee5988af1ac47",
      "1658a39ec2454a8b87a1e3d5f74b6547",
      "d3983c4a21aa4fe283ec14bcf47051a8",
      "ed84c0035f314729a8bfee72af85c4d6",
      "371207f4b3454a508a8eeb9664eb269d",
      "20eafa8077c74d0fb5238c413b3e232a",
      "7a4e4f6538344c87bd6f8b497000afc5",
      "371eee8bd9164e32bd823783cd8df88e",
      "695731add568416194b47cc64110da1b",
      "aa285a14a35d402dac97e5ec3b867fa7",
      "7a2a65af032b44e2885fcb3b10cb8905",
      "d4f8a2a342014866a1d875e0e4dcb923",
      "54af43b6f5cc42bbb3b375fa36c649f3",
      "0adae4dc59dd47dd80c253db13e2ac29",
      "ccedf2b0686a4b199154aa35bae28382",
      "5d9d95cdaf18419db52cb73ebec31fdf",
      "0bd1dfde68f64a62bbf10d6cc91717e5",
      "84d00b2ed99d42bb93509062e4b11fee",
      "1a549e59e9774992a3b1146832fdab91"
     ]
    },
    "id": "nvXxpfNCGER2",
    "outputId": "7b59a1b9-3453-45ff-c15b-50dc8c100e78"
   },
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 279\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 8\n",
    "TEST_BATCH_SIZE = 8\n",
    "\n",
    "LEARNING_RATE = 5e-5\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\", truncation=True, do_lower_case=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AT44vKls9nf3",
    "outputId": "cf59909e-11b5-4939-ff0f-53b1dcf7328b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n",
      "None None\n",
      "<|endoftext|> 50256\n",
      "<|endoftext|> 50256\n"
     ]
    }
   ],
   "source": [
    "# Some of the common BERT tokens\n",
    "print(tokenizer.sep_token, tokenizer.sep_token_id) # marker for ending of a sentence\n",
    "print(tokenizer.cls_token, tokenizer.cls_token_id) # start of each sentence, so BERT knows we’re doing classification\n",
    "print(tokenizer.pad_token, tokenizer.pad_token_id) # special token for padding\n",
    "print(tokenizer.unk_token, tokenizer.unk_token_id) # tokens not found in training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3vWRDemOGxJD"
   },
   "outputs": [],
   "source": [
    "class SentimentData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.Phrase\n",
    "        self.targets = self.data.Sentiment\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True,\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An intermittently pleasing but mostly routine ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intermittently pleasing but mostly routine effort</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intermittently pleasing but mostly routine</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33141</th>\n",
       "      <td>mistaking the filmmaker in the tall grass ,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33142</th>\n",
       "      <td>mistaking the filmmaker in the tall grass</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33143</th>\n",
       "      <td>mistaking the filmmaker</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33144</th>\n",
       "      <td>mistaking</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33145</th>\n",
       "      <td>the filmmaker</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33146 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Phrase  Sentiment\n",
       "0      An intermittently pleasing but mostly routine ...          2\n",
       "1      An intermittently pleasing but mostly routine ...          2\n",
       "2                                                     An          2\n",
       "3      intermittently pleasing but mostly routine effort          2\n",
       "4             intermittently pleasing but mostly routine          2\n",
       "...                                                  ...        ...\n",
       "33141        mistaking the filmmaker in the tall grass ,          2\n",
       "33142          mistaking the filmmaker in the tall grass          2\n",
       "33143                            mistaking the filmmaker          2\n",
       "33144                                          mistaking          2\n",
       "33145                                      the filmmaker          2\n",
       "\n",
       "[33146 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.dropna()\n",
    "df_test = df_test.dropna()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_data=df_train.sample(frac=train_size,random_state=200)\n",
    "valid_data=df_train.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([], dtype='int64')\n",
      "Int64Index([404], dtype='int64')\n",
      "Int64Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "print(train_data[train_data['Phrase'] == ' '].index)\n",
    "print(valid_data[valid_data['Phrase'] == ' '].index)\n",
    "print(test_data[test_data['Phrase'] == ' '].index)\n",
    "len(valid_data)\n",
    "valid_data = valid_data.drop(404)\n",
    "valid_data= valid_data.reset_index(drop=True)\n",
    "\n",
    "test_data = test_data.drop(1390)\n",
    "test_data= test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Dataset: (62424, 2)\n",
      "VALID Dataset: (15604, 2)\n",
      "TEST Dataset: (33146, 2)\n"
     ]
    }
   ],
   "source": [
    "train_set = SentimentData(train_data, tokenizer, MAX_LEN)\n",
    "valid_set = SentimentData(valid_data, tokenizer, MAX_LEN)\n",
    "test_set = SentimentData(test_data, tokenizer, MAX_LEN)\n",
    "\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"VALID Dataset: {}\".format(valid_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(df_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "9fc198d13d7f33dc70588c3f22bc7b7c4f4ebb45",
    "id": "c1tInLk2Eadt"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 4\n",
    "                }\n",
    "\n",
    "valid_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 4\n",
    "                }\n",
    "test_params = {'batch_size': TEST_BATCH_SIZE,\n",
    "               'shuffle': True,\n",
    "                'num_workers': 4\n",
    "                }\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_set, **train_params)\n",
    "valid_loader = DataLoader(valid_set, **valid_params)\n",
    "test_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "cb8f194ee79d76356be0002b0e18f947e1412d66",
    "id": "HMqQTafXEaei"
   },
   "outputs": [],
   "source": [
    "class GPTNeoClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GPTNeoClass, self).__init__()\n",
    "        self.l1 = GPTNeoModel.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "        self.pre_classifier = torch.nn.Linear(2048, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZ55mIPZIkp_",
    "outputId": "8c4259dc-8e8e-4691-a12e-dda63c2746cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPTNeoModel were not initialized from the model checkpoint at EleutherAI/gpt-neo-1.3B and are newly initialized: ['transformer.h.1.attn.attention.bias', 'transformer.h.21.attn.attention.bias', 'transformer.h.13.attn.attention.bias', 'transformer.h.15.attn.attention.bias', 'transformer.h.9.attn.attention.bias', 'transformer.h.11.attn.attention.bias', 'transformer.h.3.attn.attention.bias', 'transformer.h.19.attn.attention.bias', 'transformer.h.23.attn.attention.bias', 'transformer.h.7.attn.attention.bias', 'transformer.h.17.attn.attention.bias', 'transformer.h.5.attn.attention.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTNeoClass(\n",
       "  (l1): GPTNeoModel(\n",
       "    (wte): Embedding(50257, 2048)\n",
       "    (wpe): Embedding(2048, 2048)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (18): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (19): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (20): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (21): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (22): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (23): GPTNeoBlock(\n",
       "        (ln_1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPTNeoAttention(\n",
       "          (attention): GPTNeoSelfAttention(\n",
       "            (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ln_2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPTNeoMLP(\n",
       "          (c_fc): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (c_proj): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=2048, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTNeoClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XYZ7YuJ5InOS"
   },
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "EPOCHS = 1\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "tpmo2RxdCeGE"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function for a single training iteration\n",
    "def train_epoch(model, training_loader, loss_fn, optimizer, device, n_examples):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    step = 0\n",
    "    for d in tqdm(training_loader):\n",
    "        step = step+1\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "        \n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        correct_predictions += torch.sum(preds == targets)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        # Backward prop\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Descent\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        #scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "2S_C8Ka7C7D1"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(data_loader):\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            # Get model ouptuts\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-x7C-1aF7fb",
    "outputId": "765bbdab-3381-41f5-bb68-de50b2a9357f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7803/7803 [2:44:11<00:00,  1.26s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.2527776115042697 accuracy 0.5214180443419197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 1393/1951 [09:14<03:42,  2.51it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 128, in collate\n    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 128, in <dictcomp>\n    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:27\u001b[0m\n",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(model, data_loader, loss_fn, device, n_examples)\u001b[0m\n\u001b[1;32m      5\u001b[0m correct_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m tqdm(data_loader):\n\u001b[1;32m      9\u001b[0m         input_ids \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     10\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 61, in fetch\n    return self.collate_fn(data)\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 265, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 128, in collate\n    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 128, in <dictcomp>\n    return elem_type({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 120, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n  File \"/home/csci8523/hwan0259/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py\", line 162, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\nRuntimeError: Trying to resize storage that is not resizable\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Show details \n",
    "    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        len(train_set)\n",
    "    )\n",
    "    \n",
    "    print(f\"Train loss {train_loss} accuracy {train_acc}\")\n",
    "    \n",
    "    # Get model performance (accuracy and loss)\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        valid_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(valid_set)\n",
    "    )\n",
    "    \n",
    "    print(f\"Val   loss {val_loss} accuracy {val_acc}\")\n",
    "    print()\n",
    "    \n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    # If we beat prev performance\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'GPTNeo_SA_Model')\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1951/1951 [12:44<00:00,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 1.2232231805564073 accuracy 0.5292873622148168\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get model performance (accuracy and loss)\n",
    "val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    valid_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(valid_set)\n",
    ")\n",
    "    \n",
    "print(f\"Val   loss {val_loss} accuracy {val_acc}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 hours 40 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPbLEHAVJG7y",
    "outputId": "bffbf585-1de3-4f63-de1a-f743c40af34a"
   },
   "outputs": [],
   "source": [
    "list1= []\n",
    "for t_ac in history['train_acc']:\n",
    "    t_ac = torch.Tensor.cpu(t_ac).numpy()\n",
    "    list1.append(t_ac)\n",
    "\n",
    "list2= []\n",
    "for t_va in history['val_acc']:\n",
    "    t_va = torch.Tensor.cpu(t_va).numpy()\n",
    "    list2.append(t_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "WxGKEizcHjTd",
    "outputId": "d4565d70-7edf-4a9b-ea49-6a36f07a8fbc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training and validation accuracy\n",
    "\n",
    "plt.plot(list1, label='train accuracy')\n",
    "plt.plot(list2, label='validation accuracy')\n",
    "\n",
    "# Graph chars\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'GPTNeo_SA_Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGPTNeo_SA_Model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/pytorch_gpu/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GPTNeo_SA_Model'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('GPTNeo_SA_Model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6DK-g8jUJqRP",
    "outputId": "197838d5-a9af-49a4-a8e7-2e0a42a623ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4143/4143 [27:18<00:00,  2.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get model performance (accuracy and loss)\n",
    "test_acc, test_loss = eval_model(\n",
    "  model,\n",
    "  test_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.940622737146995"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZvpFmHiPMvS"
   },
   "outputs": [],
   "source": [
    "#Example of sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEVr6X7LPJBz"
   },
   "outputs": [],
   "source": [
    "review_text = \"I love completing my todos! Best app ever!!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MVJ8ZRpPJYM"
   },
   "outputs": [],
   "source": [
    "encoded_review = tokenizer.encode_plus(\n",
    "    review_text,\n",
    "    max_length=MAX_LEN,\n",
    "    add_special_tokens=True,\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8S6mnJPkPJhh"
   },
   "outputs": [],
   "source": [
    "# sentiment\n",
    "# 0 - 4\n",
    "# one of five labels (from very negative to very positive)\n",
    "\n",
    "input_ids = encoded_review['input_ids'].to(device)\n",
    "attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "\n",
    "output = model(input_ids, attention_mask)\n",
    "_, prediction = torch.max(output, dim=1)\n",
    "\n",
    "print(f'Review text: {review_text}')\n",
    "print(f'Sentiment  : {prediction.item()}')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0adae4dc59dd47dd80c253db13e2ac29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0bd1dfde68f64a62bbf10d6cc91717e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0e9457ca4249484697572c3b07cb3d21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_657c1c6a696b47e0a92a84a2a1672604",
      "placeholder": "​",
      "style": "IPY_MODEL_639b7315d6ca4a7384d2a2a3306c75b0",
      "value": " 232k/232k [00:00&lt;00:00, 209kB/s]"
     }
    },
    "11ba5b834bda4174a2f3d9d4f36881c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1658a39ec2454a8b87a1e3d5f74b6547": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17da5e15286b47c9a7bec9592111b72f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a549e59e9774992a3b1146832fdab91": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "20eafa8077c74d0fb5238c413b3e232a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "371207f4b3454a508a8eeb9664eb269d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "371eee8bd9164e32bd823783cd8df88e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c7fc2c48f9b439dbfe73cf74de76c8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "54af43b6f5cc42bbb3b375fa36c649f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d9d95cdaf18419db52cb73ebec31fdf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "639b7315d6ca4a7384d2a2a3306c75b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "657c1c6a696b47e0a92a84a2a1672604": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65cdd43e32084e11b028b9dcc0da682a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d3983c4a21aa4fe283ec14bcf47051a8",
      "placeholder": "​",
      "style": "IPY_MODEL_ed84c0035f314729a8bfee72af85c4d6",
      "value": "Downloading: 100%"
     }
    },
    "695731add568416194b47cc64110da1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aa285a14a35d402dac97e5ec3b867fa7",
       "IPY_MODEL_7a2a65af032b44e2885fcb3b10cb8905",
       "IPY_MODEL_d4f8a2a342014866a1d875e0e4dcb923"
      ],
      "layout": "IPY_MODEL_54af43b6f5cc42bbb3b375fa36c649f3"
     }
    },
    "715932841e174fdba262ba1e5ae5f5c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "795103d24e494175be849536604a154f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_371207f4b3454a508a8eeb9664eb269d",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20eafa8077c74d0fb5238c413b3e232a",
      "value": 28
     }
    },
    "7a2a65af032b44e2885fcb3b10cb8905": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d9d95cdaf18419db52cb73ebec31fdf",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0bd1dfde68f64a62bbf10d6cc91717e5",
      "value": 570
     }
    },
    "7a4e4f6538344c87bd6f8b497000afc5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80599af641ca43509eab85f43069c2b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_715932841e174fdba262ba1e5ae5f5c6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef665c9eee4942598abcb1be9588dd94",
      "value": 231508
     }
    },
    "84d00b2ed99d42bb93509062e4b11fee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ed024db83014418a687d99091e5fce2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_65cdd43e32084e11b028b9dcc0da682a",
       "IPY_MODEL_795103d24e494175be849536604a154f",
       "IPY_MODEL_d4a912c8a844499d8f0ee5988af1ac47"
      ],
      "layout": "IPY_MODEL_1658a39ec2454a8b87a1e3d5f74b6547"
     }
    },
    "aa285a14a35d402dac97e5ec3b867fa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0adae4dc59dd47dd80c253db13e2ac29",
      "placeholder": "​",
      "style": "IPY_MODEL_ccedf2b0686a4b199154aa35bae28382",
      "value": "Downloading: 100%"
     }
    },
    "ccedf2b0686a4b199154aa35bae28382": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3983c4a21aa4fe283ec14bcf47051a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4a912c8a844499d8f0ee5988af1ac47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a4e4f6538344c87bd6f8b497000afc5",
      "placeholder": "​",
      "style": "IPY_MODEL_371eee8bd9164e32bd823783cd8df88e",
      "value": " 28.0/28.0 [00:00&lt;00:00, 497B/s]"
     }
    },
    "d4f8a2a342014866a1d875e0e4dcb923": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84d00b2ed99d42bb93509062e4b11fee",
      "placeholder": "​",
      "style": "IPY_MODEL_1a549e59e9774992a3b1146832fdab91",
      "value": " 570/570 [00:00&lt;00:00, 7.89kB/s]"
     }
    },
    "ed84c0035f314729a8bfee72af85c4d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef665c9eee4942598abcb1be9588dd94": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f3c039795b634c1b89ece4a35815533e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f94c8764e7eb4245b64bcc20b2cf2f9f",
       "IPY_MODEL_80599af641ca43509eab85f43069c2b9",
       "IPY_MODEL_0e9457ca4249484697572c3b07cb3d21"
      ],
      "layout": "IPY_MODEL_17da5e15286b47c9a7bec9592111b72f"
     }
    },
    "f94c8764e7eb4245b64bcc20b2cf2f9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11ba5b834bda4174a2f3d9d4f36881c3",
      "placeholder": "​",
      "style": "IPY_MODEL_4c7fc2c48f9b439dbfe73cf74de76c8b",
      "value": "Downloading: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
